{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook shows how to read the fastMRI dataset and apply some simple transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from fastmri import evaluate\n",
    "import torch\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file corresponds to one MRI scan and contains the k-space data, ground truth and some meta data related to the scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = 'example_data/example1.h5'\n",
    "hf = h5py.File(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Keys:', list(hf.keys()))\n",
    "print('Attrs:', dict(hf.attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multi-coil MRIs, k-space has the following shape:\n",
    "(number of slices, number of coils, height, width)\n",
    "\n",
    "For single-coil MRIs, k-space has the following shape:\n",
    "(number of slices, height, width)\n",
    "\n",
    "MRIs are acquired as 3D volumes, the first dimension is the number of 2D slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "volume_kspace = hf['kspace'][()]\n",
    "#volume_kspace2 = hf2['kspace'][()]\n",
    "#volume_kspace3 = hf3['kspace'][()]\n",
    "print(volume_kspace.dtype)\n",
    "print(volume_kspace.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_kspace = volume_kspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the absolute value of k-space looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_multiple_slices(data, slice_nums, cmap=None):\n",
    "    fig = plt.figure()\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        image = data[num]\n",
    "        #print(image.shape)\n",
    "        length = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        pad_l = (length - 320)//2\n",
    "        pad_w = (width - 320)//2\n",
    "        true_image = image[pad_l:(length-pad_l), pad_w:(width-pad_w)]\n",
    "        plt.imshow(true_image, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def show_slice(data, cmap=None):\n",
    "    #fig = plt.figure()\n",
    "    #plt.imshow(data, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_slices(np.log(np.abs(slice_kspace) + 1e-9), [10,20,30]) #show the 10th, 20th, and 30th slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastMRI repo contains some utlity functions to convert k-space into image space. These functions work on PyTorch Tensors. The to_tensor function can convert Numpy arrays to PyTorch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastmri\n",
    "from fastmri.data import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_kspace2 = T.to_tensor(slice_kspace)      # Convert from numpy array to pytorch tensor\n",
    "slice_image = fastmri.ifft2c(slice_kspace2)           # Apply Inverse Fourier Transform to get the complex image\n",
    "slice_image_abs = fastmri.complex_abs(slice_image)   # Compute absolute value to get a real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_slices(slice_image_abs, [10,20,30], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MR imaging is an indirect process, whereby cross-sectional images of the subjectâ€™s anatomy are\n",
    "produced from frequency and phase measurements instead of direct, spatially-resolved measurements. As we can see, each image in the dataset focuses on a different snapshot of the subject's anatomy. These slices can be combined into the full image using the Root-Sum-of-Squares (RSS) transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_image_rss = fastmri.rss(slice_image_abs, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(slice_image_rss.numpy()), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = 'fastmri_examples/unet/output_test/reconstructions/file1000022.h5'\n",
    "hf_r = h5py.File(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Keys:', list(hf_r.keys()))\n",
    "print('Attrs:', dict(hf_r.attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_kspace_r = torch.tensor(hf_r['reconstruction'][()].squeeze(1))\n",
    "print(volume_kspace_r.dtype)\n",
    "print(volume_kspace_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_slices(volume_kspace_r, [10,20,30], cmap='gray') #show the 10th, 20th, and 30th slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_image_rss = fastmri.rss(volume_kspace_r, dim=0)\n",
    "plt.imshow(np.abs(slice_image_rss), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Under-Sampled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been looking at fully-sampled data. We can simulate under-sampled data by creating a mask and applying it to k-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri.data.subsample import RandomMaskFunc\n",
    "mask_func = RandomMaskFunc(center_fractions=[0.04], accelerations=[8])  # Create the mask function object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_kspace, mask, _ = T.apply_mask(slice_kspace2, mask_func)   # Apply the mask to k-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the subsampled image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_image = fastmri.ifft2c(masked_kspace)           # Apply Inverse Fourier Transform to get the complex image\n",
    "sampled_image_abs = fastmri.complex_abs(sampled_image)   # Compute absolute value to get a real image\n",
    "sampled_image_rss = fastmri.rss(sampled_image_abs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(sampled_image_rss.numpy()), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Reconstruction Error (L1, NMSE, PSNR, SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an emulated single-coil (ESC) methodology to simulate single-coil data from a multi-coil\n",
    "acquisition [43]. ESC computes a complex-valued linear combination of the responses from multiple\n",
    "coils, with the linear combination fitted to the ground-truth root-sum-of-squares reconstruction in\n",
    "the least-squares sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def recon_errors(original_dir, recon_dir):\n",
    "    # assign directory\n",
    "    #directory = 'fastmri_examples/unet/output_test/reconstructions'\n",
    "    \n",
    "    l1 = []\n",
    "    nmse = []\n",
    "    psnr = []\n",
    "    ssim = []\n",
    "\n",
    "    # iterate over files in\n",
    "    # that directory\n",
    "    for filename in os.listdir(recon_dir):\n",
    "\n",
    "        #testing image (the original)\n",
    "        val_image = f'{original_dir}/{filename}'\n",
    "        hf = h5py.File(val_image)\n",
    "        val_kspace = hf['kspace'][()]\n",
    "        slice_kspace2 = T.to_tensor(val_kspace)      # Convert from numpy array to pytorch tensor\n",
    "        slice_image = fastmri.ifft2c(slice_kspace2)           # Apply Inverse Fourier Transform to get the complex image\n",
    "        slice_image_abs = fastmri.complex_abs(slice_image)   # Compute absolute value to get a real image\n",
    "        length = slice_image_abs.shape[1]\n",
    "        width = slice_image_abs.shape[2]\n",
    "        pad_l = (length - 320)//2\n",
    "        pad_w = (width - 320)//2\n",
    "        true_image = slice_image_abs[:,pad_l:(length-pad_l), pad_w:(width-pad_w)]\n",
    "\n",
    "        #reconstructed image\n",
    "        recon_image = f'{recon_dir}/{filename}'\n",
    "        recon_hf = h5py.File(recon_image)\n",
    "        pred_image = torch.tensor(recon_hf['reconstruction'][()].squeeze(1))\n",
    "        \n",
    "        #l1_loss\n",
    "        l1.append(F.l1_loss(true_image, pred_image))\n",
    "\n",
    "        #nmse\n",
    "        nmse.append(evaluate.nmse(true_image.numpy(), pred_image.numpy()))\n",
    "\n",
    "        #psnr\n",
    "        psnr.append(evaluate.psnr(true_image.numpy(), pred_image.numpy()))\n",
    "\n",
    "        #ssmr\n",
    "        ssim.append(evaluate.ssim(true_image.numpy(), pred_image.numpy()))\n",
    "    \n",
    "    return np.mean(l1), np.mean(nmse), np.mean(psnr), np.mean(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_l1, mean_nmse, mean_psnr, mean_ssim = recon_errors(\"../data/singlecoil_test\",'fastmri_examples/unet/output_test/reconstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_nmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impact-mri-py3.10",
   "language": "python",
   "name": "impact-mri-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
