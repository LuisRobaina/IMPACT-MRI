{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the Time Complexity of U-Net and Attention Unet under Different Configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from models.unet import UNet\n",
    "from models.attn_unet import AttentionUnet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # use GPU if available\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_forward_time(model:torch.nn.Module, input_tensor:torch.Tensor):\n",
    "    start_time = time.time()\n",
    "    out = model(input_tensor)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(unet, attn_unet, num_trials=100):\n",
    "    # Prepare the input\n",
    "\n",
    "    input_shape=(1, 38, 640, 368)\n",
    "    # single coil data: ( batch, number of slices, height, width)\n",
    "    input_tensor = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    unet = unet.to(device)\n",
    "    attn_unet = attn_unet.to(device)\n",
    "\n",
    "    unet.eval()\n",
    "    attn_unet.eval()\n",
    "    \n",
    "    times_unet = []\n",
    "    times_attn_unet = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # do not store gradients as it is run in inference mode...\n",
    "        for _ in range(num_trials):\n",
    "            unet_time = measure_forward_time(unet, input_tensor)\n",
    "            attn_unet_time = measure_forward_time(att_unet, input_tensor)\n",
    "            \n",
    "            times_unet.append(unet_time)\n",
    "            times_attn_unet.append(attn_unet_time)\n",
    "            print(\"times: \", (unet_time, attn_unet_time))\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title('(Eval Mode) Forward Pass Time Comparison')\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.plot(times_unet[1:], 'r', label='UNet')\n",
    "    plt.plot(times_attn_unet[1:], 'b', label='AttentionUNet')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_hparams = dict(\n",
    "    in_chans = 38,\n",
    "    out_chans = 38,\n",
    "    chans = 32,\n",
    "    num_pool_layers = 4,\n",
    "    drop_prob = 0.0,\n",
    ")\n",
    "unet = UNet(\n",
    "    **shared_hparams\n",
    ")\n",
    "att_unet = AttentionUnet(\n",
    "    **shared_hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(att_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(unet, att_unet, num_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_memory_required(model):\n",
    "    # source: https://pytorch.org/docs/stable/index.html\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    return total_params * 4 / (1024 ** 2)  # return in size in MB\n",
    "\n",
    "def compare_model_memory(unet, attn_unet):\n",
    "    memory_unet = model_memory_required(unet)\n",
    "    memory_attn_unet = model_memory_required(attn_unet)\n",
    "    # x labels\n",
    "    models = ['UNet', 'AttnUNet']\n",
    "    memory = [memory_unet, memory_attn_unet]\n",
    "    \n",
    "    diff = memory_attn_unet - memory_unet \n",
    "    print(diff)\n",
    "    plt.bar(models, memory, color=['red', 'blue'])\n",
    "    plt.ylabel('Memory (MB)')\n",
    "    plt.title('Parameter Memory Comparison Between UNet and AttnUnet')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model_memory(unet, att_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impact-mri-py3.10",
   "language": "python",
   "name": "impact-mri-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
